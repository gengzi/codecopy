[toc]

## 订单微服务
业务场景：订单微服务表现有数据1000万，每日预计新增10万数据，计划分库分表缓解数据库压力



### 单体服务

生成订单功能
预扣商品库存，生成订单数据





### 分布分表服务

分析订单表细节
用户查询订单，


订单号，生成规则   时间戳+userid后四位+随机数3 位 基本不冲突  
商品号 ：前端传入


2 的 三十二次方。





一致hash算法
分库 
uid mod 32
2   20  先10 个节点，进入 1 库， 后10个节点，进入 2 库

4   20  前 5 个节点，进入1 库，
旧数据，需要将1库 数据拆出来


一致性hash  和 传统hash的比较和思考

一致性hash ，通过分散节点，顺时针查找选择 映射的真实节点
传统hash: 通过固定模，hash 得到真实节点
容错性： 当某一台真实节点服务宕机，对于传统hash ，这台服务都阻塞
当现有服务节点，发生变更，传统涉及全部服务节点的变更，重新计算，才能正常设置和获取数据
一致性hash ，仅有变更节点到顺时针最近节点的数据的设置和获取发生变更。影响范围更小。


对于数据库分片来说，分为几种情况，一种是数据库宕机了，一种是数据库新增了，一种是数据库删除一台
数据库如果宕机，需要剔除服务吗？ 我觉得不现实。动态的移除当前数据库实例，把现有数据执行操作到了其他库。
我觉得会造成数据污染和失败，因为数据并没有迁移，对老数据的操作，会报错。对于新数据的操作，会直接执行到其他库。
后续，这个数据库实例上线后，将导致数据不一致的问题，需要刷新整个业务数据库，恢复数据。
假如说不动态删除宕机的服务实例，情况跟传统hash 一致。如下；
如果采用传统hash ，执行到这个库的所有操作，都将失败。其他库数据，还能继续操作。影响一部分客户。可以接受，及时恢复数据库实例即可。

数据库如果新增一台实例，也就是当前分库分表不满足业务了，需要新增节点。
那必然有数据迁移的操作，一致性hash ，迁移的数据，仅仅是新增节点逆时针到最近节点的数据，这一部分数据，需要迁移到新增节点的库中。
那么就需要评估出，那些数据段的数据迁移。好评估吗？ 计算所有虚拟新增节点顺时针最近的原有节点数据，通过hash计算，删除数据，并填充数据到新节点。
对于传统hash，所有实例的数据都要根据新公式，重新计算一遍数据节点，每个库都可能会新增数据和删除数据。

如果删除一台实例，可能么？很小，一致性hash 需要迁移虚拟节点逆时针最新一个节点的数据，
对于传统hash，跟新增一样，所有数据，需要重新计算一遍数据节点，每个库都可能会新增和删除数据。



