server:
  port: 8089
spring:
  application:
    name: codecopy
  profiles:
    # 可以配置多个。逗号分隔
    active: dev,dev_luckdraw,dev_https
    #active: dev,devshardingbyInline_encryption,dev_elasticsearch
#  datasource:
#    # 注意mysql 时区 字符集编码
#    url: jdbc:mysql://127.0.0.1:3306/sqltest?autoReconnect=true&serverTimezone=Asia/Shanghai
#    username: root
#    password: 111
#    type: com.alibaba.druid.pool.DruidDataSource
    # redis 配置
  redis:
    host: localhost
    port: 6379
    jedis.pool.max-wait: -1ms
    timeout: 2000ms
    redisson:
      config: classpath:redisson.yml
  jpa: #jpa配置
    properties:
      hibernate.dialect: org.hibernate.dialect.MySQL5Dialect
      hibernate.current_session_context_class: org.springframework.orm.hibernate5.SpringSessionContext
    hibernate:
      ddl-auto: none
    show-sql: true
  # 通过默认配置，配置 cache 相关
#  shardingsphere:
#    # 显示sql
#    props:
#      sql:
#        show: true
#
#    datasource:
#      # 配置两个数据源
#      names: ds0,ds1,slaveds0,slaveds1
#      # ds0 数据源
#      ds0:
#        type: com.alibaba.druid.pool.DruidDataSource
#        driver-class-name: com.mysql.jdbc.Driver
#        url: jdbc:mysql://127.0.0.1:3306/ds0?autoReconnect=true&serverTimezone=Asia/Shanghai
#        username: root
#        password: 111
#      # ds1 数据源
#      ds1:
#        type: com.alibaba.druid.pool.DruidDataSource
#        driver-class-name: com.mysql.jdbc.Driver
#        url: jdbc:mysql://127.0.0.1:3306/ds1?autoReconnect=true&serverTimezone=Asia/Shanghai
#        username: root
#        password: 111
#      slaveds0:
#        type: com.alibaba.druid.pool.DruidDataSource
#        driver-class-name: com.mysql.jdbc.Driver
#        url: jdbc:mysql://127.0.0.1:3307/ds0?autoReconnect=true&serverTimezone=Asia/Shanghai
#        username: root
#        password:
#      slaveds1:
#        type: com.alibaba.druid.pool.DruidDataSource
#        driver-class-name: com.mysql.jdbc.Driver
#        url: jdbc:mysql://127.0.0.1:3307/ds1?autoReconnect=true&serverTimezone=Asia/Shanghai
#        username: root
#        password:
#
#      ### 特别注意： 做分片的字段，必须是能够执行 行表达式的， 比如 id 分片，id 是根据雪花算法生成的，那么实体 bean 中的id 类型应该是 long
#    ## No signature of method: java.lang.String.mod() 错误就是 进行分片是，计算分片的字段类型 有问题导致的
#    ## 版本号，参与分片。  算法是 dataVersion % 2 , 那么这个类型，就不能是 String ，否则会导致错误  No signature of method: java.lang.String.mod()
#    ## 需要设置为 integer 类型
#    ###
#    sharding:
#      # https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/configuration/config-spring-boot/#%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87--%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB
#      master-slave-rules:
#        # master-slave-data-source-name 主从数据库名称
#        ds0:
#          master-data-source-name: ds0
#          slave-data-source-names: slaveds0
#        ds1:
#          master-data-source-name: ds1
#          slave-data-source-names: slaveds1
#      # 默认的数据源名称
#      default-data-source-name: ds0
#      # 主键生成策略
#      key-generators:
#        snowflake:
#          type: SNOWFLAKE
#      # 绑定表
#      binding-tables: t_bussiness
#      # 广播表 配置为广播表，会在执行插入 更新时，都每个数据库都执行
#      broadcast-tables: shorturl,area_info,dic_data,dic_list,sys_permission
#      # 默认的数据库策略
#      default-database-strategy:   # 分库策略
#        inline:
#          # 数据分片的列
#          sharding-column: data_version
#          # 分片算法  算法根据 userid 除以2 来区分
#          algorithm-expression: ds$->{data_version % 2}
#      # 表配置
#      tables:   # 分表策略
#        # 业务表
#        t_bussiness:
#          # 主键生成策略
#          key-generator:
#            # 列
#            column: id
#            # 生成算法
#            type: SNOWFLAKE
#            props:
#              worker:
#                id: 123
#          # 实际数据节点
#          actual-data-nodes: ds$->{0..1}.t_bussiness$->{0..1}
#          # 表策略
#          table-strategy:
#            inline:
#              # 分片列
#              sharding-column: id
#              # 分片算法
#              algorithm-expression: t_bussiness$->{id % 2}

      #        # 用户表

      #        sys_users:
#          key-generate-strategy:
#            column: ID
#            key-generator-name: snowflake
#          actual-data-nodes: ds$->{0..1}.sys_users$->{0..1}
#          table-strategy:
#            inline:
#              sharding-column: ID
#              algorithm-expression: sys_users$->{ID % 2}





#  cache:
#    type: caffeine
#    caffeine:
#      # 配置缓存,初始缓存容量为10,最大容量为200,过期时间(这里配置写入后过期时间为3秒)
#      spec: initialCapacity=10,maximumSize=200,expireAfterWrite=3s

# 短链接
shorturl:
  # 短链接前缀
  pre: http://localhost:8089/u/

# token 认证相关
token:
  # Hmac 密钥
  hmacKey: codecopy
  # aes 密钥
  aeskey: f24fea293ac8bd5a6439f3ca3df746ae
  # rsa 公钥
  publickey: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALbcdLKOtTKOjalffv/LLLOqfyh8Ep4XHjvOivMU3Nb1N0puG4+NTrXBS8GDczgsZ+7J6D7FTcH8JInMKpz85LMCAwEAAQ==
  # rsa 密钥
  secretkey: MIIBVAIBADANBgkqhkiG9w0BAQEFAASCAT4wggE6AgEAAkEAttx0so61Mo6NqV9+/8sss6p/KHwSnhceO86K8xTc1vU3Sm4bj41OtcFLwYNzOCxn7snoPsVNwfwkicwqnPzkswIDAQABAkBGw9Xda+Cvaf9kdnJdZzErbmW7Mxi5WVT37BxVqdM01BTjudKSADlLn53fEeWl7pmfMkMuXZ7uPNdqmLWVLMNxAiEA6LXvDTKtEZNyTvjXs4nDJweiIT9kZtZmYD3hVcQueJUCIQDJKV+PcdKehVw8U+hdeE4/NZDFCHRzaGM4Zs5YRRbuJwIgSG0fSn9EKB04zWVbVNCCgWo5xplBOVRvJnL758KYKAUCIDdpmzZDb3ZVXCwOHRMqYbuNwNxV0OY9mh9eSncMSR2/AiEApSModT03Kr+nHxhgzAyOvzLcKE0IPMJ+ny3mjdyBjWc=
  url:
    # 远程校验token 的服务地址
    validToken:  http://localhost:8089/api/v1/validToken


# service redis-server restart redis
redis:
  subsection:
    # 分段发号器的key
    subkey: onenum
    # 发号器初始化 号码
    initValue: 101
    # 发号器 增加步长
    step: 20

# springboot actuator 监控
management:
  endpoints:
    web:
      exposure:
        # 开放所有的端点
        include: "*"

# 由于一个 yml 里面配置过多，将一些配置，配置在自定义的yml 中，使用java config 加载到spring 容器
yml-include:
  names: redis.yml,application-pro.yml